name: Daily repository report

on:
  schedule:
    - cron: '0 0 * * *'  # Daily at 00:00 UTC
  workflow_dispatch:

jobs:
  repo-report:
    runs-on: ubuntu-latest
    env:
      OWNER: EvezArt
      REPORT_TOKEN: ${{ secrets.REPORT_TOKEN }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
      
      - name: Install dependencies
        run: pip install requests
      
      - name: Generate repository report
        run: |
          cat > fetch_repos.py << 'EOF'
          import os
          import sys
          import json
          import csv
          import time
          import requests
          from typing import Optional, Dict, List, Any

          GRAPHQL_ENDPOINT = "https://api.github.com/graphql"
          OWNER = os.environ.get("OWNER", "EvezArt")
          REPORT_TOKEN = os.environ.get("REPORT_TOKEN")

          def get_headers() -> Dict[str, str]:
              """Build headers for GraphQL API requests."""
              headers = {
                  "Content-Type": "application/json",
              }
              if REPORT_TOKEN:
                  headers["Authorization"] = f"Bearer {REPORT_TOKEN}"
              return headers

          def exponential_backoff(attempt: int, base_delay: float = 1.0) -> float:
              """Calculate exponential backoff delay."""
              return min(base_delay * (2 ** attempt), 60)

          def is_transient_error(status_code: Optional[int], error_type: Optional[str]) -> bool:
              """Check if error is transient and should be retried."""
              if status_code in [502, 503, 504]:
                  return True
              if error_type in ["RATE_LIMITED", "SECONDARY_RATE_LIMITED"]:
                  return True
              return False

          def execute_graphql_query(query: str, variables: Dict[str, Any], max_retries: int = 5) -> Dict[str, Any]:
              """Execute GraphQL query with retry logic."""
              headers = get_headers()
              
              for attempt in range(max_retries):
                  try:
                      response = requests.post(
                          GRAPHQL_ENDPOINT,
                          json={"query": query, "variables": variables},
                          headers=headers,
                          timeout=30
                      )
                      
                      # Check for transient HTTP errors
                      if response.status_code in [502, 503, 504]:
                          delay = exponential_backoff(attempt)
                          print(f"Transient error {response.status_code}, retrying in {delay}s...", file=sys.stderr)
                          time.sleep(delay)
                          continue
                      
                      # Non-transient HTTP error
                      if response.status_code != 200:
                          print(f"HTTP error {response.status_code}: {response.text}", file=sys.stderr)
                          sys.exit(1)
                      
                      data = response.json()
                      
                      # Check for GraphQL errors
                      if "errors" in data:
                          errors = data["errors"]
                          # Check if any error is a rate limit
                          for error in errors:
                              error_type = error.get("type")
                              if is_transient_error(None, error_type):
                                  delay = exponential_backoff(attempt)
                                  print(f"Rate limit error, retrying in {delay}s...", file=sys.stderr)
                                  time.sleep(delay)
                                  break
                          else:
                              # No transient errors found, it's a fatal error
                              print(f"GraphQL errors: {json.dumps(errors, indent=2)}", file=sys.stderr)
                              sys.exit(1)
                          continue
                      
                      return data
                      
                  except requests.exceptions.RequestException as e:
                      if attempt < max_retries - 1:
                          delay = exponential_backoff(attempt)
                          print(f"Request exception: {e}, retrying in {delay}s...", file=sys.stderr)
                          time.sleep(delay)
                          continue
                      else:
                          print(f"Request failed after {max_retries} attempts: {e}", file=sys.stderr)
                          sys.exit(1)
              
              print(f"Failed after {max_retries} retries", file=sys.stderr)
              sys.exit(1)

          def fetch_all_repositories() -> List[Dict[str, Any]]:
              """Fetch all repositories for the owner using pagination."""
              query = """
              query($owner: String!, $cursor: String) {
                repositoryOwner(login: $owner) {
                  repositories(first: 100, after: $cursor) {
                    pageInfo {
                      hasNextPage
                      endCursor
                    }
                    nodes {
                      name
                      nameWithOwner
                      isPrivate
                      url
                      description
                      defaultBranchRef {
                        name
                      }
                      createdAt
                      updatedAt
                      pushedAt
                      stargazerCount
                      forkCount
                      diskUsage
                      repositoryTopics(first: 100) {
                        nodes {
                          topic {
                            name
                          }
                        }
                      }
                      licenseInfo {
                        name
                      }
                      primaryLanguage {
                        name
                      }
                      owner {
                        login
                      }
                      visibility
                      isArchived
                      isTemplate
                      isFork
                      issues {
                        totalCount
                      }
                      watchers {
                        totalCount
                      }
                    }
                  }
                }
              }
              """
              
              repositories = []
              cursor = None
              page = 0
              
              while True:
                  page += 1
                  print(f"Fetching page {page}...", file=sys.stderr)
                  
                  variables = {"owner": OWNER, "cursor": cursor}
                  data = execute_graphql_query(query, variables)
                  
                  # Extract repository data
                  repo_owner = data.get("data", {}).get("repositoryOwner")
                  if not repo_owner:
                      print(f"No repository owner found for {OWNER}", file=sys.stderr)
                      break
                  
                  repos_data = repo_owner.get("repositories", {})
                  nodes = repos_data.get("nodes", [])
                  
                  for node in nodes:
                      if node:  # Filter out null nodes
                          repositories.append(node)
                  
                  # Check pagination
                  page_info = repos_data.get("pageInfo", {})
                  has_next_page = page_info.get("hasNextPage", False)
                  
                  if not has_next_page:
                      break
                  
                  cursor = page_info.get("endCursor")
              
              print(f"Fetched {len(repositories)} repositories", file=sys.stderr)
              return repositories

          def transform_repository_data(repos: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
              """Transform raw GraphQL data into simplified format."""
              transformed = []
              
              for repo in repos:
                  # Extract topics
                  topics_nodes = repo.get("repositoryTopics", {}).get("nodes", [])
                  topics = [node.get("topic", {}).get("name") for node in topics_nodes if node]
                  
                  # Extract default branch
                  default_branch_ref = repo.get("defaultBranchRef")
                  default_branch = default_branch_ref.get("name") if default_branch_ref else None
                  
                  # Extract license
                  license_info = repo.get("licenseInfo")
                  license_name = license_info.get("name") if license_info else None
                  
                  # Extract primary language
                  primary_language = repo.get("primaryLanguage")
                  language_name = primary_language.get("name") if primary_language else None
                  
                  transformed_repo = {
                      "name": repo.get("name"),
                      "nameWithOwner": repo.get("nameWithOwner"),
                      "isPrivate": repo.get("isPrivate"),
                      "visibility": repo.get("visibility"),
                      "isArchived": repo.get("isArchived"),
                      "isTemplate": repo.get("isTemplate"),
                      "isFork": repo.get("isFork"),
                      "url": repo.get("url"),
                      "description": repo.get("description"),
                      "defaultBranch": default_branch,
                      "createdAt": repo.get("createdAt"),
                      "updatedAt": repo.get("updatedAt"),
                      "pushedAt": repo.get("pushedAt"),
                      "stargazerCount": repo.get("stargazerCount"),
                      "forkCount": repo.get("forkCount"),
                      "diskUsage": repo.get("diskUsage"),
                      "openIssuesCount": repo.get("issues", {}).get("totalCount"),
                      "watchersCount": repo.get("watchers", {}).get("totalCount"),
                      "topics": topics,
                      "license": license_name,
                      "primaryLanguage": language_name,
                      "owner": repo.get("owner", {}).get("login")
                  }
                  
                  transformed.append(transformed_repo)
              
              return transformed

          def write_json_report(repos: List[Dict[str, Any]], filename: str = "repo-report.json"):
              """Write repository data to JSON file."""
              with open(filename, 'w', encoding='utf-8') as f:
                  json.dump(repos, f, indent=2, ensure_ascii=False)
              print(f"JSON report written to {filename}", file=sys.stderr)

          def write_csv_report(repos: List[Dict[str, Any]], filename: str = "repo-report.csv"):
              """Write repository data to CSV file."""
              if not repos:
                  print("No repositories to write", file=sys.stderr)
                  return
              
              fieldnames = [
                  "name", "nameWithOwner", "isPrivate", "visibility", "isArchived",
                  "isTemplate", "isFork", "url", "description", "defaultBranch",
                  "createdAt", "updatedAt", "pushedAt", "stargazerCount", "forkCount",
                  "diskUsage", "openIssuesCount", "watchersCount", "topics", "license",
                  "primaryLanguage", "owner"
              ]
              
              with open(filename, 'w', encoding='utf-8', newline='') as f:
                  writer = csv.DictWriter(f, fieldnames=fieldnames)
                  writer.writeheader()
                  
                  for repo in repos:
                      # Convert topics list to semicolon-delimited string
                      row = repo.copy()
                      topics = row.get("topics", [])
                      row["topics"] = ";".join(topics) if topics else ""
                      writer.writerow(row)
              
              print(f"CSV report written to {filename}", file=sys.stderr)

          def main():
              """Main execution function."""
              print(f"Fetching repositories for owner: {OWNER}", file=sys.stderr)
              
              if not REPORT_TOKEN:
                  print("Warning: REPORT_TOKEN not set, only public repositories will be accessible", file=sys.stderr)
              
              # Fetch repositories
              raw_repos = fetch_all_repositories()
              
              # Transform data
              repos = transform_repository_data(raw_repos)
              
              # Write reports
              write_json_report(repos)
              write_csv_report(repos)
              
              print("Repository report generation complete!", file=sys.stderr)

          if __name__ == "__main__":
              main()
          EOF
          
          python fetch_repos.py
      
      - name: Upload JSON report
        uses: actions/upload-artifact@v4
        with:
          name: repo-report.json
          path: repo-report.json
      
      - name: Upload CSV report
        uses: actions/upload-artifact@v4
        with:
          name: repo-report.csv
          path: repo-report.csv
